{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176aabdb-e81b-4f3d-afcd-f34a0b952eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hvory\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
      "Python 3.12.4\n",
      "Requirement already satisfied: diffusers in c:\\users\\hvory\\appdata\\roaming\\python\\python312\\site-packages (0.31.0)\n",
      "Requirement already satisfied: importlib-metadata in d:\\anaconda\\lib\\site-packages (from diffusers) (7.0.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from diffusers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in d:\\anaconda\\lib\\site-packages (from diffusers) (0.26.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from diffusers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hvory\\appdata\\roaming\\python\\python312\\site-packages (from diffusers) (11.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.2->diffusers) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: diffusers\n",
      "Version: 0.31.0\n",
      "Summary: State-of-the-art diffusion in PyTorch and JAX.\n",
      "Home-page: https://github.com/huggingface/diffusers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/diffusers/graphs/contributors)\n",
      "Author-email: diffusers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: C:\\Users\\hvory\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
      "Requires: filelock, huggingface-hub, importlib-metadata, numpy, Pillow, regex, requests, safetensors\n",
      "Required-by: \n",
      "Requirement already satisfied: diffusers in c:\\users\\hvory\\appdata\\roaming\\python\\python312\\site-packages (0.31.0)\n",
      "Requirement already satisfied: importlib-metadata in d:\\anaconda\\lib\\site-packages (from diffusers) (7.0.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from diffusers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in d:\\anaconda\\lib\\site-packages (from diffusers) (0.26.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from diffusers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hvory\\appdata\\roaming\\python\\python312\\site-packages (from diffusers) (11.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.2->diffusers) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!export PATH=$PATH:/users/shoseini/.local/bin\n",
    "#!echo $PATH\n",
    "!python -m site --user-site\n",
    "#!pip install --user diffusers\n",
    "#!python3.9 -m venv paper2 # python3.8 -m venv env\n",
    "#!python -m ipykernel install --user --name=paper2 --display-name \"Python (paper2)\"\n",
    "#!which virtualenv\n",
    "#!virtualenv /scratch/project_2012241/mnist/paper2\n",
    "#!pip list\n",
    "#!pip install diffusers\n",
    "!python --version\n",
    "#!pip list\n",
    "!pip install diffusers --user\n",
    "!pip show diffusers\n",
    "#!export PATH=$PATH:~/.local/bin\n",
    "#!source ~/.bashrc\n",
    "!pip install  diffusers --prefix=./mnist/paper2/lib64/python3.9/site-packages/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31488170-36ac-4ad3-af5b-693fa97052d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in c:\\users\\hvory\\appdata\\roaming\\python\\python312\\site-packages (0.31.0)\n",
      "Requirement already satisfied: importlib-metadata in d:\\anaconda\\lib\\site-packages (from diffusers) (7.0.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from diffusers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in d:\\anaconda\\lib\\site-packages (from diffusers) (0.26.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from diffusers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hvory\\appdata\\roaming\\python\\python312\\site-packages (from diffusers) (11.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.2->diffusers) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install diffusers\n",
    "#!pip cache purge\n",
    "#!pip install --upgrade diffusers transformers\n",
    "#!pip install --upgrade diffusers transformers\n",
    "#!pip install --user transformers\n",
    "!pip  install diffusers --user\n",
    "#!pip install accelerate\n",
    "from diffusers.models.autoencoders import AutoencoderKL\n",
    "from transformers import AutoImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8610f267-eba9-4a23-8a71-13229165d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from diffusers import UNet2DModel\n",
    "from diffusers import DDPMScheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from accelerate import Accelerator\n",
    "#from diffusers.utils.hub_utils import init_git_repo, push_to_hub\n",
    "from datetime import datetime\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "import math\n",
    "from accelerate import notebook_launcher\n",
    "from diffusers import DDPMPipeline\n",
    "import glob\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "from diffusers import DiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "faa606a6-b9b4-4720-bd9e-15e70d394f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 28  # the generated image resolution\n",
    "    train_batch_size = 16 #48\n",
    "    eval_batch_size = 16 #48  # how many images to sample during evaluation\n",
    "    test_batch_size=1\n",
    "    num_epochs = 35\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 5\n",
    "    save_model_epochs = 5\n",
    "    mixed_precision = 'fp16'  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir ='C:\\\\Users\\\\hvory\\\\ISSBA-main\\\\MNist\\\\mnist'  # the model namy locally and on the HF Hub\n",
    "    log_dir=\"log\"\n",
    "    workers = 4\n",
    "\n",
    "    push_to_hub = True  # whether to upload the saved model to the HF Hub\n",
    "    hub_private_repo = False\n",
    "    overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6fc54c33-2441-4b9c-b87b-427f7f54fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243\n",
      "19888\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            #transforms.RandomRotation(20),\n",
    "           # transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((64, 64)),\n",
    "            #transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "        ])\n",
    "    }\n",
    "data_dir=\"C:\\\\Users\\\\hvory\\\\ISSBA-main\\\\MNist\\\\mnist\"\n",
    "#bd_data_dir= \"/scratch/project_2012241/bd_dataset/\"\n",
    "image_datasets = {'train': datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms['train'])}\n",
    "#poison_datasets= {x: datasets.ImageFolder(os.path.join(bd_data_dir, x), data_transforms[x])\n",
    "                   # for x in ['train', 'val']}\n",
    "#print(image_datasets)\n",
    "#weights = [0.7]* len(image_datasets['train']) + [0.3] * len(poison_datasets['train'])\n",
    "#print(weights)\n",
    "#print([0.7] * len(image_datasets['train']))\n",
    "# Create a WeightedRandomSampler to control the proportions\n",
    "#sampler = WeightedRandomSampler(weights, len(weights))\n",
    "#sampler = WeightedRandomSampler(weights, num_samples=70000, replacement=True)\n",
    "#combined_dataset = ConcatDataset([image_datasets, poison_datasets])\n",
    "#combined_dataset = ConcatDataset([image_datasets['train'], poison_datasets['train']])\n",
    "#print(len(combined_dataset))\n",
    "train_loader = data.DataLoader(image_datasets['train'], batch_size=config.train_batch_size, shuffle=False, num_workers=config.workers)\n",
    "print(len(train_loader))\n",
    "print(len(image_datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d914a91d-9047-436b-93ce-26643acc611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2DModel(\n",
    "    sample_size=config.image_size,  # the target image resolution\n",
    "    in_channels=3,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=3,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channes for each UNet block\n",
    "    down_block_types=( \n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\", \n",
    "        \"DownBlock2D\", \n",
    "        \"DownBlock2D\", \n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ), \n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\", \n",
    "        \"UpBlock2D\", \n",
    "        \"UpBlock2D\", \n",
    "        \"UpBlock2D\"  \n",
    "      ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f313f329-b32c-4f89-87f1-2d4f4ecadf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hvory\\AppData\\Local\\Temp\\ipykernel_17760\\2232307372.py:12: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(16, 4))\n",
    "for i, (image, label) in enumerate(image_datasets['train']):\n",
    "\n",
    "    axs[i].imshow(image.permute(1, 2, 0).numpy())\n",
    "    axs[i].set_axis_off()\n",
    "    axs[i].set_title(f\"Label: {label}\")\n",
    "\n",
    "\n",
    "    if i >= 4: break\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "64f24998-a463-4b56-b6c4-890d6fb6f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(len(train_loader) * config.num_epochs),\n",
    ")\n",
    "def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler):\n",
    "    # Initialize accelerator and tensorboard logging, A list of loggers to be\n",
    "    #setup for experiment tracking. Should be one or several of:\"all\",\"tensorboard\",\"wandb\"\n",
    "    accelerator = Accelerator(\n",
    "        mixed_precision=config.mixed_precision,\n",
    "        gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "        log_with=\"tensorboard\",\n",
    "        project_dir=os.path.join(config.log_dir, \"logs\")\n",
    "    )\n",
    "    if accelerator.is_main_process:\n",
    "        #if config.push_to_hub:\n",
    "            #repo = init_git_repo(config, at_init=True)\n",
    "       # accelerator.init_trackers(\"train_example\", log_with=\"tensorboard\", logging_dir=os.path.join(config.output_dir, \"logs\"))\n",
    "        accelerator.init_trackers(\"train_example\")\n",
    "       # accelerator.init_trackers(\"train_example\")#, logging_dir=config.output_dir)\n",
    "       \n",
    "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(model, optimizer, train_dataloader, lr_scheduler)\n",
    "    global_step = 0\n",
    "    starttime = datetime.now()\n",
    "    total_batches = len(train_dataloader) * config.num_epochs\n",
    "\n",
    "\n",
    "\n",
    "    # Now you train the model\n",
    "    for epoch in range(config.num_epochs):\n",
    "        progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            clean_images = batch[0]\n",
    "            # Sample noise to add to the images\n",
    "            noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
    "            bs = clean_images.shape[0]\n",
    "            \n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device).long()\n",
    "            \n",
    "            # Add noise to the clean images according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "           \n",
    "            with accelerator.accumulate(model):\n",
    "                # Predict the noise residual\n",
    "                #print(noisy_images.shape)\n",
    "                noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "                \n",
    "                loss = F.mse_loss(noise_pred, noise)\n",
    "                accelerator.backward(loss)\n",
    "\n",
    "                accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            elapsed = datetime.now() - starttime\n",
    "            total = elapsed * total_batches / global_step\n",
    "\n",
    "            logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            accelerator.log(logs, step=global_step)\n",
    "            \n",
    "        # After each epoch you optionally sample some demo images with evaluate() and save the model\n",
    "        if accelerator.is_main_process:\n",
    "            pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
    "\n",
    "            if (epoch + 1) % config.save_image_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "                torch.autograd.set_detect_anomaly(True)\n",
    "                evaluate(config, epoch, pipeline)\n",
    "\n",
    "            if (epoch + 1) % config.save_model_epochs == 0 or epoch == config.num_epochs - 1:\n",
    "                #if config.push_to_hub:\n",
    "                    #push_to_hub(config, pipeline, repo, commit_message=f\"Epoch {epoch}\", blocking=True)\n",
    "               # else:\n",
    "                    pipeline.save_pretrained(config.output_dir) \n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "564d8cf6-34b9-4983-8ef8-1b157f39aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(images, rows, cols):\n",
    "    w, h = images[0].size  # Get dimensions of the first image\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))  # create new blank image\n",
    "    for i, image in enumerate(images):  # Paste images into the grid\n",
    "        grid.paste(image, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "def evaluate(config, epoch, pipeline):\n",
    "    # config.eval_batch_size:This parameter specifies the number of images to generate in one batch.\n",
    "    # The default pipeline output type is `List[PIL.Image]`\n",
    "    #torch.manual_seed(config.seed):\n",
    "    #you ensure that the image generation process can produce consistent results each time the code is run with the same seed\n",
    "    #The .images attribute retrieves the generated images directly, typically as a tensor or a list of image objects.\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    images = pipeline(\n",
    "        batch_size=config.eval_batch_size,\n",
    "        generator=torch.manual_seed(config.seed),\n",
    "    ).images\n",
    "\n",
    "    # Make a grid out of the images\n",
    "    image_grid = make_grid(images, rows=4, cols=4)\n",
    "\n",
    "    # Save the images\n",
    "    test_dir = os.path.join(config.output_dir, \"samples\") # create folder samples\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    image_grid.save(f\"{test_dir}/{epoch:04d}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8eb6a96f-ffe5-447c-b2c2-9752df3cae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce67af044b574ae790af4a9cdaf8b948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'MseLossBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m (config, model, noise_scheduler, optimizer, train_loader, lr_scheduler)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\launchers.py:266\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[1;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching training on CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 266\u001b[0m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[171], line 57\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)\u001b[0m\n\u001b[0;32m     54\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m model(noisy_images, timesteps, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(noise_pred, noise)\n\u001b[1;32m---> 57\u001b[0m \u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m accelerator\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\accelerator.py:2237\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[0;32m   2239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\paper\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\paper\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\paper\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'MseLossBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "args = (config, model, noise_scheduler, optimizer, train_loader, lr_scheduler)\n",
    "\n",
    "notebook_launcher(train_loop, args, num_processes=1)\n",
    "#num_processes: This should be set to the number of processes (GPUs) you want to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbb877-692a-48c5-bf8b-ecbbbdf5510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = DiffusionPipeline.from_pretrained(\"output_dir\").unet.to(\"cuda\")\n",
    "def show(tensor):\n",
    "    return Image.fromarray((tensor.permute(0, 2, 3, 1) * 255.0).type(torch.uint8).numpy()[0])\n",
    "\n",
    "#show(sample_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717635e0-8692-4bde-b41b-924ea4f2dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Add noise\n",
    "noise_level = 100 #50\n",
    "\n",
    "def noise(img, t):\n",
    "    noise = torch.randn(img.shape)#.to(device)\n",
    "    timesteps = torch.LongTensor([t])#.to(device)\n",
    "    noisy_image = noise_scheduler.add_noise(img, noise, timesteps)\n",
    "    return noisy_image\n",
    "\n",
    "noisy_image = noise(sample_image, noise_level)\n",
    "print(sample_image.size)\n",
    "print(noisy_image.shape)\n",
    "save_image(noisy_image, \"denoised_images/noisy_image.png\")\n",
    "#show(noisy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557a5ee-c14a-4d4c-b8da-964ab77ed68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def denoise(img, ts, progress=True):\n",
    "    noise_scheduler.set_timesteps(1000)\n",
    "    img_reconstruct = img[0].unsqueeze(0).to(\"cuda\")\n",
    "    #img_reconstruct = img.reshape(1, 3, config.image_size, config.image_size).to(\"cuda\")\n",
    "\n",
    "    for t in tqdm(noise_scheduler.timesteps[-ts:], disable=not progress):\n",
    "        # 1. predict noise model_output\n",
    "        model_output = trained_model(img_reconstruct, t).sample\n",
    "\n",
    "        # 2. compute previous img_reconstruct: x_t -> x_t-1\n",
    "        img_reconstruct = noise_scheduler.step(model_output, t, img_reconstruct).prev_sample\n",
    "        #print(reconstructed)\n",
    "    return img_reconstruct\n",
    "\n",
    "\n",
    "img_reconstruct = denoise(noisy_image, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43177b-0236-40c0-9bf3-0668929f1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = img_reconstruct.detach().cpu()\n",
    "print(type(reconstructed))\n",
    "#reconstructed.save(\"denoised_images\")\n",
    "save_image(reconstructed, \"denoised_images/saved_image.png\")\n",
    "#show(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffed9d-ea66-4398-80e7-13895cf2a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "images = dict(\n",
    "    sample_image=sample_image,\n",
    "    noisy_image=noisy_image,\n",
    "    reconstructed=reconstructed,\n",
    ")\n",
    "\n",
    "for i, (title, image) in enumerate(images.items()):\n",
    "    axs[i].imshow(show(image))\n",
    "    axs[i].set_axis_off()\n",
    "    axs[i].set_title(title)\n",
    "fig.suptitle(f\"Reconstruction at $t=${noise_level}\", fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb950a10-2399-45d5-a4ca-7240d9bae9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(img, t):\n",
    "    noise = torch.randn(img.shape)#.to(device)\n",
    "    timesteps = torch.LongTensor([t])#.to(device)\n",
    "    noisy_image = noise_scheduler.add_noise(img, noise, timesteps)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6289078-d7f3-4b4d-927b-601fb7c6c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def denoise(img, ts, progress=True):\n",
    "    noise_scheduler.set_timesteps(1_000)\n",
    "    img_reconstruct = img[0].unsqueeze(0).to(\"cuda\")\n",
    "    #img_reconstruct = img.reshape(1, 3, config.image_size, config.image_size).to(\"cuda\")\n",
    "\n",
    "    for t in tqdm(noise_scheduler.timesteps[-ts:], disable=not progress):\n",
    "        # 1. predict noise model_output\n",
    "        model_output = trained_model(img_reconstruct, t).sample\n",
    "\n",
    "        # 2. compute previous img_reconstruct: x_t -> x_t-1\n",
    "        img_reconstruct = noise_scheduler.step(model_output, t, img_reconstruct).prev_sample\n",
    "\n",
    "    return img_reconstruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42984a6f-691f-4f92-994a-325ec7a175db",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level = 100 #50\n",
    "from PIL import Image\n",
    "import shutil\n",
    "lst_dir=[]\n",
    "#test_loader = data.DataLoader(image_datasets['train'], batch_size=config.test_batch_size, shuffle=True, num_workers=config.workers)\n",
    "for idx, (originImg, label) in enumerate(image_datasets['train']):\n",
    "        file_path = image_datasets['train'].samples[idx][0]\n",
    "        file_name = os.path.splitext(os.path.basename(file_path))[0]    #[0]\n",
    "        originImg=originImg.unsqueeze(0)\n",
    "        os.makedirs(\"clean_dataset\", exist_ok=True)\n",
    "        noisy_image = noise(originImg, noise_level)\n",
    "        img_reconstruct = denoise(noisy_image, noise_level)\n",
    "        reconstructed = img_reconstruct.detach().cpu()\n",
    "        folder_path = os.path.join('/scratch/project_2012241/mnist' , 'train') \n",
    "        newfile= file_name\n",
    "        lst_dir.append(newfile)\n",
    "        os.makedirs(folder_path + \"\\\\\" + newfile, exist_ok=True)\n",
    "        newfolder=os.path.join(folder_path,newfile)\n",
    "        Image.fromarray((noisy_image.permute(0, 2, 3, 1) * 255).type(torch.uint8).numpy()[0])\n",
    "        image_path = os.path.join(newfolder, file_name + \".png\")\n",
    "        save_image(reconstructed, image_path)\n",
    "        os.makedirs(folder_path + \"\\\\\" + newfile, exist_ok=True)\n",
    "        newfolder=os.path.join(folder_path,newfile)\n",
    "        image_path = os.path.join(newfolder, file_name + \".png\")\n",
    "        save_image(reconstructed, image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
